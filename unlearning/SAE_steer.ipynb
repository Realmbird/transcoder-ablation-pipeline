{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "login(token=\"\")\n",
    "os.environ[\"HF_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51cb71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 1: Install dependencies (run once)\n",
    "# ============================================================\n",
    "# !pip install sae-lens transformer-lens einops beartype jaxtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169dedf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chriskino/.local/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/chriskino/.local/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 2: Imports\n",
    "# ============================================================\n",
    "import os\n",
    "from typing import Any, List, Tuple\n",
    "\n",
    "import einops\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from beartype import beartype\n",
    "from jaxtyping import Bool, Float, Int, jaxtyped\n",
    "from sae_lens import SAE\n",
    "from tqdm import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c967e607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 3: SAE-Bench Helper Functions\n",
    "# ============================================================\n",
    "\n",
    "LLM_NAME_TO_BATCH_SIZE = {\n",
    "    \"pythia-70m-deduped\": 512,\n",
    "    \"pythia-160m-deduped\": 256,\n",
    "    \"gemma-2-2b\": 32,\n",
    "    \"gemma-2-9b\": 32,\n",
    "    \"gemma-2-2b-it\": 32,\n",
    "    \"gemma-2-9b-it\": 32,\n",
    "}\n",
    "\n",
    "LLM_NAME_TO_DTYPE = {\n",
    "    \"pythia-70m-deduped\": \"float32\",\n",
    "    \"pythia-160m-deduped\": \"float32\",\n",
    "    \"gemma-2-2b\": \"bfloat16\",\n",
    "    \"gemma-2-2b-it\": \"bfloat16\",\n",
    "    \"gemma-2-9b\": \"bfloat16\",\n",
    "    \"gemma-2-9b-it\": \"bfloat16\",\n",
    "}\n",
    "\n",
    "@jaxtyped(typechecker=beartype)\n",
    "@torch.no_grad\n",
    "def get_bos_pad_eos_mask(\n",
    "    tokens: Int[torch.Tensor, \"dataset_size seq_len\"], tokenizer: AutoTokenizer | Any\n",
    ") -> Bool[torch.Tensor, \"dataset_size seq_len\"]:\n",
    "    \"\"\"Create mask that excludes BOS, PAD, and EOS tokens.\"\"\"\n",
    "    mask = (\n",
    "        (tokens == tokenizer.pad_token_id)\n",
    "        | (tokens == tokenizer.eos_token_id)\n",
    "        | (tokens == tokenizer.bos_token_id)\n",
    "    ).to(dtype=torch.bool)\n",
    "    return ~mask\n",
    "\n",
    "\n",
    "@jaxtyped(typechecker=beartype)\n",
    "@torch.no_grad\n",
    "def get_feature_activation_sparsity(\n",
    "    tokens: Int[torch.Tensor, \"dataset_size seq_len\"],\n",
    "    model: HookedTransformer,\n",
    "    sae: SAE | Any,\n",
    "    batch_size: int,\n",
    "    layer: int,\n",
    "    hook_name: str,\n",
    "    mask_bos_pad_eos_tokens: bool = False,\n",
    ") -> Float[torch.Tensor, \"d_sae\"]:\n",
    "    \"\"\"Get the activation sparsity for each SAE feature.\"\"\"\n",
    "    device = sae.device\n",
    "    running_sum_F = torch.zeros(sae.W_dec.shape[0], dtype=torch.float32, device=device)\n",
    "    total_tokens = 0\n",
    "\n",
    "    for i in tqdm(range(0, tokens.shape[0], batch_size), desc=\"Computing sparsity\"):\n",
    "        tokens_BL = tokens[i : i + batch_size]\n",
    "        _, cache = model.run_with_cache(\n",
    "            tokens_BL, stop_at_layer=layer + 1, names_filter=hook_name\n",
    "        )\n",
    "        resid_BLD: Float[torch.Tensor, \"batch seq_len d_model\"] = cache[hook_name]\n",
    "\n",
    "        sae_act_BLF: Float[torch.Tensor, \"batch seq_len d_sae\"] = sae.encode(resid_BLD)\n",
    "        # Convert to binary (active or not)\n",
    "        sae_act_BLF = (sae_act_BLF > 0).to(dtype=torch.float32)\n",
    "\n",
    "        if mask_bos_pad_eos_tokens:\n",
    "            attn_mask_BL = get_bos_pad_eos_mask(tokens_BL, model.tokenizer)\n",
    "        else:\n",
    "            attn_mask_BL = torch.ones_like(tokens_BL, dtype=torch.bool)\n",
    "\n",
    "        attn_mask_BL = attn_mask_BL.to(device=sae_act_BLF.device)\n",
    "        sae_act_BLF = sae_act_BLF * attn_mask_BL[:, :, None]\n",
    "        total_tokens += attn_mask_BL.sum().item()\n",
    "\n",
    "        running_sum_F += einops.reduce(sae_act_BLF, \"B L F -> F\", \"sum\")\n",
    "\n",
    "    return running_sum_F / total_tokens\n",
    "\n",
    "\n",
    "@jaxtyped(typechecker=beartype)\n",
    "@torch.no_grad\n",
    "def collect_sae_activations(\n",
    "    tokens: Int[torch.Tensor, \"dataset_size seq_len\"],\n",
    "    model: HookedTransformer,\n",
    "    sae: SAE | Any,\n",
    "    batch_size: int,\n",
    "    layer: int,\n",
    "    hook_name: str,\n",
    "    mask_bos_pad_eos_tokens: bool = False,\n",
    "    selected_latents: list[int] | None = None,\n",
    "    activation_dtype: torch.dtype | None = None,\n",
    ") -> Float[torch.Tensor, \"dataset_size seq_len indexed_d_sae\"]:\n",
    "    \"\"\"Collects SAE activations for a given set of tokens.\"\"\"\n",
    "    sae_acts = []\n",
    "\n",
    "    for i in tqdm(range(0, tokens.shape[0], batch_size), desc=\"Collecting SAE activations\"):\n",
    "        tokens_BL = tokens[i : i + batch_size]\n",
    "        _, cache = model.run_with_cache(\n",
    "            tokens_BL, stop_at_layer=layer + 1, names_filter=hook_name\n",
    "        )\n",
    "        resid_BLD: Float[torch.Tensor, \"batch seq_len d_model\"] = cache[hook_name]\n",
    "\n",
    "        sae_act_BLF: Float[torch.Tensor, \"batch seq_len d_sae\"] = sae.encode(resid_BLD)\n",
    "\n",
    "        if selected_latents is not None:\n",
    "            sae_act_BLF = sae_act_BLF[:, :, selected_latents]\n",
    "\n",
    "        if mask_bos_pad_eos_tokens:\n",
    "            attn_mask_BL = get_bos_pad_eos_mask(tokens_BL, model.tokenizer)\n",
    "        else:\n",
    "            attn_mask_BL = torch.ones_like(tokens_BL, dtype=torch.bool)\n",
    "\n",
    "        attn_mask_BL = attn_mask_BL.to(device=sae_act_BLF.device)\n",
    "        sae_act_BLF = sae_act_BLF * attn_mask_BL[:, :, None]\n",
    "\n",
    "        if activation_dtype is not None:\n",
    "            sae_act_BLF = sae_act_BLF.to(dtype=activation_dtype)\n",
    "\n",
    "        sae_acts.append(sae_act_BLF)\n",
    "\n",
    "    return torch.cat(sae_acts, dim=0)\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47bb9d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gemma-2-2b with dtype=bfloat16...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcce02ba7d247f38628656be42f789e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-2b into HookedTransformer\n",
      "‚úÖ Loaded model: gemma-2-2b\n",
      "   Layers: 26, d_model: 2304\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 4: Load Model with TransformerLens\n",
    "# ============================================================\n",
    "\n",
    "MODEL_NAME = \"gemma-2-2b\"\n",
    "DTYPE = LLM_NAME_TO_DTYPE.get(MODEL_NAME, \"bfloat16\")\n",
    "BATCH_SIZE = LLM_NAME_TO_BATCH_SIZE.get(MODEL_NAME, 32)\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} with dtype={DTYPE}...\")\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    dtype=DTYPE,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Loaded model: {MODEL_NAME}\")\n",
    "print(f\"   Layers: {model.cfg.n_layers}, d_model: {model.cfg.d_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77502472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE: gemma-scope-2b-pt-res/layer_12/width_16k/average_l0_71...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ID layer_12/width_16k/average_l0_71 not found in release gemma-scope-2b-pt-res. Valid IDs are ['embedding/width_4k/average_l0_6', 'embedding/width_4k/average_l0_44', 'embedding/width_4k/average_l0_21', 'embedding/width_4k/average_l0_111', 'layer_0/width_16k/average_l0_105', ...]. If you don't want to specify an L0 value, consider using release gemma-scope-2b-pt-res-canonical which has valid IDs ['layer_0/width_16k/canonical', 'layer_1/width_16k/canonical', 'layer_2/width_16k/canonical', 'layer_3/width_16k/canonical', 'layer_4/width_16k/canonical', ...]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m SAE_ID = \u001b[33m\"\u001b[39m\u001b[33mlayer_12/width_16k/average_l0_71\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Choose layer and width\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading SAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAE_RELEASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAE_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m sae, cfg_dict, sparsity = \u001b[43mSAE\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelease\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSAE_RELEASE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43msae_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSAE_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Get layer and hook info\u001b[39;00m\n\u001b[32m     22\u001b[39m LAYER = sae.cfg.hook_layer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/transcoder/lib/python3.12/site-packages/sae_lens/saes/sae.py:567\u001b[39m, in \u001b[36mSAE.from_pretrained\u001b[39m\u001b[34m(cls, release, sae_id, device, force_download, converter)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_pretrained\u001b[39m(\n\u001b[32m    552\u001b[39m     \u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[T_SAE],\n\u001b[32m   (...)\u001b[39m\u001b[32m    557\u001b[39m     converter: PretrainedSaeHuggingfaceLoader | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    558\u001b[39m ) -> T_SAE:\n\u001b[32m    559\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[33;03m    Load a pretrained SAE from the Hugging Face model hub.\u001b[39;00m\n\u001b[32m    561\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    565\u001b[39m \u001b[33;03m        device: The device to load the SAE on.\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained_with_cfg_and_sparsity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/transcoder/lib/python3.12/site-packages/sae_lens/saes/sae.py:625\u001b[39m, in \u001b[36mSAE.from_pretrained_with_cfg_and_sparsity\u001b[39m\u001b[34m(cls, release, sae_id, device, force_download, converter)\u001b[39m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    623\u001b[39m         str_valid_ids = \u001b[38;5;28mstr\u001b[39m(valid_ids)\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    626\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msae_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in release \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelease\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Valid IDs are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstr_valid_ids\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    627\u001b[39m         + value_suffix\n\u001b[32m    628\u001b[39m     )\n\u001b[32m    630\u001b[39m conversion_loader = (\n\u001b[32m    631\u001b[39m     converter\n\u001b[32m    632\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m NAMED_PRETRAINED_SAE_LOADERS[get_conversion_loader_name(release)]\n\u001b[32m    633\u001b[39m )\n\u001b[32m    634\u001b[39m repo_id, folder_name = get_repo_id_and_folder_name(release, sae_id)\n",
      "\u001b[31mValueError\u001b[39m: ID layer_12/width_16k/average_l0_71 not found in release gemma-scope-2b-pt-res. Valid IDs are ['embedding/width_4k/average_l0_6', 'embedding/width_4k/average_l0_44', 'embedding/width_4k/average_l0_21', 'embedding/width_4k/average_l0_111', 'layer_0/width_16k/average_l0_105', ...]. If you don't want to specify an L0 value, consider using release gemma-scope-2b-pt-res-canonical which has valid IDs ['layer_0/width_16k/canonical', 'layer_1/width_16k/canonical', 'layer_2/width_16k/canonical', 'layer_3/width_16k/canonical', 'layer_4/width_16k/canonical', ...]"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 5: Load SAE from SAE-Lens (Gemma Scope)\n",
    "# ============================================================\n",
    "\n",
    "# Available Gemma-2-2b SAEs on SAE-Lens:\n",
    "# - \"gemma-scope-2b-pt-res\" (residual stream)\n",
    "# - \"gemma-scope-2b-pt-mlp\" (MLP output)\n",
    "# - \"gemma-scope-2b-pt-att\" (attention output)\n",
    "\n",
    "SAE_RELEASE = \"gemma-scope-2b-pt-res\"  # or \"gemma-scope-2b-pt-mlp\"\n",
    "SAE_ID = \"layer_12/width_16k/average_l0_71\"  # Choose layer and width\n",
    "\n",
    "print(f\"Loading SAE: {SAE_RELEASE}/{SAE_ID}...\")\n",
    "\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=SAE_RELEASE,\n",
    "    sae_id=SAE_ID,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# Get layer and hook info\n",
    "LAYER = sae.cfg.hook_layer\n",
    "HOOK_NAME = sae.cfg.hook_name\n",
    "\n",
    "print(f\"‚úÖ Loaded SAE:\")\n",
    "print(f\"   Release: {SAE_RELEASE}\")\n",
    "print(f\"   SAE ID: {SAE_ID}\")\n",
    "print(f\"   Layer: {LAYER}\")\n",
    "print(f\"   Hook: {HOOK_NAME}\")\n",
    "print(f\"   d_sae: {sae.cfg.d_sae}\")\n",
    "print(f\"   d_in: {sae.cfg.d_in}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 6: Load and Tokenize Datasets\n",
    "# ============================================================\n",
    "\n",
    "def load_and_tokenize_dataset(\n",
    "    dataset_name: str,\n",
    "    tokenizer,\n",
    "    max_samples: int = 500,\n",
    "    max_length: int = 128,\n",
    "    min_text_len: int = 50,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Load dataset and tokenize for sparsity computation.\"\"\"\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    if dataset_name == \"wikitext\":\n",
    "        raw_data = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "        for x in raw_data:\n",
    "            if len(x['text']) > min_text_len:\n",
    "                texts.append(str(x['text']))\n",
    "    else:\n",
    "        # Support full names like \"cais/wmdp-bio-forget-corpus\"\n",
    "        full_name = dataset_name if \"/\" in dataset_name else f\"cais/wmdp-{dataset_name}\"\n",
    "        dataset = load_dataset(full_name, split=\"train\", token=os.getenv(\"HF_TOKEN\"))\n",
    "        for line in dataset:\n",
    "            if len(line['text']) > min_text_len:\n",
    "                texts.append(str(line['text']))\n",
    "    \n",
    "    # Limit samples\n",
    "    if len(texts) > max_samples:\n",
    "        import random\n",
    "        random.seed(42)\n",
    "        texts = random.sample(texts, max_samples)\n",
    "    \n",
    "    print(f\"  Loaded {len(texts)} texts from {dataset_name}\")\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    )[\"input_ids\"]\n",
    "    \n",
    "    return tokens.to(\"cuda\")\n",
    "\n",
    "# ============================================================\n",
    "# Configure datasets\n",
    "# ============================================================\n",
    "FORGET_DATASET = \"cais/wmdp-bio-forget-corpus\"\n",
    "RETAIN_DATASET = \"wikitext\"\n",
    "MAX_SAMPLES = 500\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "print(f\"Loading FORGET dataset: {FORGET_DATASET}\")\n",
    "forget_tokens = load_and_tokenize_dataset(\n",
    "    FORGET_DATASET, model.tokenizer, MAX_SAMPLES, MAX_LENGTH\n",
    ")\n",
    "\n",
    "print(f\"Loading RETAIN dataset: {RETAIN_DATASET}\")\n",
    "retain_tokens = load_and_tokenize_dataset(\n",
    "    RETAIN_DATASET, model.tokenizer, MAX_SAMPLES, MAX_LENGTH\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Tokenized datasets:\")\n",
    "print(f\"   Forget: {forget_tokens.shape}\")\n",
    "print(f\"   Retain: {retain_tokens.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 7: Compute Feature Sparsity (SAE-Bench Method)\n",
    "# ============================================================\n",
    "\n",
    "print(\"Computing sparsity on FORGET dataset...\")\n",
    "forget_sparsity = get_feature_activation_sparsity(\n",
    "    tokens=forget_tokens,\n",
    "    model=model,\n",
    "    sae=sae,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    layer=LAYER,\n",
    "    hook_name=HOOK_NAME,\n",
    "    mask_bos_pad_eos_tokens=True,\n",
    ")\n",
    "\n",
    "print(\"\\nComputing sparsity on RETAIN dataset...\")\n",
    "retain_sparsity = get_feature_activation_sparsity(\n",
    "    tokens=retain_tokens,\n",
    "    model=model,\n",
    "    sae=sae,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    layer=LAYER,\n",
    "    hook_name=HOOK_NAME,\n",
    "    mask_bos_pad_eos_tokens=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Computed sparsity for {len(forget_sparsity)} features\")\n",
    "print(f\"   Forget: mean={forget_sparsity.mean():.4f}, max={forget_sparsity.max():.4f}\")\n",
    "print(f\"   Retain: mean={retain_sparsity.mean():.4f}, max={retain_sparsity.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 8: Select Features for Unlearning\n",
    "# ============================================================\n",
    "\n",
    "def select_unlearning_features(\n",
    "    forget_sparsity: torch.Tensor,\n",
    "    retain_sparsity: torch.Tensor,\n",
    "    retain_threshold: float = 0.01,\n",
    "    n_features: int = 50,\n",
    "    min_forget_sparsity: float = 0.001,\n",
    ") -> Tuple[torch.Tensor, dict]:\n",
    "    \"\"\"\n",
    "    Select features that are:\n",
    "    - Active on forget set (high sparsity)\n",
    "    - Inactive on retain set (low sparsity)\n",
    "    \"\"\"\n",
    "    retain_mask = retain_sparsity < retain_threshold\n",
    "    forget_mask = forget_sparsity > min_forget_sparsity\n",
    "    valid_mask = retain_mask & forget_mask\n",
    "    \n",
    "    # Score by forget/retain ratio\n",
    "    scores = forget_sparsity / (retain_sparsity + 1e-8)\n",
    "    scores[~valid_mask] = 0\n",
    "    \n",
    "    topk_values, topk_indices = torch.topk(scores, min(n_features, valid_mask.sum().item()))\n",
    "    \n",
    "    info = {\n",
    "        \"total_features\": len(forget_sparsity),\n",
    "        \"pass_retain_threshold\": retain_mask.sum().item(),\n",
    "        \"pass_forget_threshold\": forget_mask.sum().item(),\n",
    "        \"valid_candidates\": valid_mask.sum().item(),\n",
    "        \"selected\": len(topk_indices),\n",
    "    }\n",
    "    \n",
    "    return topk_indices, info\n",
    "\n",
    "# Parameters\n",
    "RETAIN_THRESHOLD = 0.01\n",
    "N_FEATURES = 50\n",
    "MIN_FORGET_SPARSITY = 0.001\n",
    "\n",
    "selected_indices, info = select_unlearning_features(\n",
    "    forget_sparsity=forget_sparsity,\n",
    "    retain_sparsity=retain_sparsity,\n",
    "    retain_threshold=RETAIN_THRESHOLD,\n",
    "    n_features=N_FEATURES,\n",
    "    min_forget_sparsity=MIN_FORGET_SPARSITY,\n",
    ")\n",
    "\n",
    "print(\"üìä Feature Selection Results:\")\n",
    "for k, v in info.items():\n",
    "    print(f\"   {k}: {v}\")\n",
    "\n",
    "print(f\"\\nüéØ Top {len(selected_indices)} Selected Features:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Index':>8} | {'Forget':>12} | {'Retain':>12} | {'Ratio':>10}\")\n",
    "print(\"-\" * 60)\n",
    "for idx in selected_indices[:15]:\n",
    "    fs = forget_sparsity[idx].item()\n",
    "    rs = retain_sparsity[idx].item()\n",
    "    ratio = fs / (rs + 1e-8)\n",
    "    print(f\"{idx.item():>8} | {fs:>12.4f} | {rs:>12.6f} | {ratio:>10.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 9: Visualize Feature Selection\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "fs_np = forget_sparsity.cpu().numpy()\n",
    "rs_np = retain_sparsity.cpu().numpy()\n",
    "sel_np = selected_indices.cpu().numpy()\n",
    "\n",
    "# Scatter plot\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(rs_np, fs_np, alpha=0.3, s=5, label=\"All features\")\n",
    "ax1.scatter(rs_np[sel_np], fs_np[sel_np], c='red', s=30, label=\"Selected\", zorder=5)\n",
    "ax1.axvline(RETAIN_THRESHOLD, color='green', linestyle='--', label=f\"Retain threshold\")\n",
    "ax1.set_xlabel(\"Retain Sparsity\")\n",
    "ax1.set_ylabel(\"Forget Sparsity\")\n",
    "ax1.set_title(f\"Feature Sparsity: {FORGET_DATASET.split('/')[-1]} vs {RETAIN_DATASET}\")\n",
    "ax1.legend()\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# Histogram\n",
    "ax2 = axes[1]\n",
    "ratios = fs_np / (rs_np + 1e-8)\n",
    "ax2.hist(np.log10(ratios + 1e-8), bins=50, alpha=0.7, edgecolor='black')\n",
    "for r in ratios[sel_np][:5]:\n",
    "    ax2.axvline(np.log10(r), color='red', alpha=0.5, linewidth=2)\n",
    "ax2.set_xlabel(\"log10(Forget/Retain Ratio)\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.set_title(\"Distribution of Forget/Retain Ratios\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d43d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 10: Apply SAE Steering for Unlearning\n",
    "# ============================================================\n",
    "\n",
    "CLAMP_VALUE = -5.0  # Negative value to suppress features\n",
    "\n",
    "def generate_with_sae_steering(\n",
    "    prompt: str,\n",
    "    model: HookedTransformer,\n",
    "    sae: SAE,\n",
    "    feature_indices: torch.Tensor,\n",
    "    clamp_value: float = -5.0,\n",
    "    max_new_tokens: int = 50,\n",
    ") -> str:\n",
    "    \"\"\"Generate text while clamping selected SAE features.\"\"\"\n",
    "    \n",
    "    def steering_hook(resid_BLD, hook):\n",
    "        # Encode through SAE\n",
    "        sae_acts = sae.encode(resid_BLD)\n",
    "        \n",
    "        # Clamp selected features\n",
    "        sae_acts[:, :, feature_indices] = clamp_value\n",
    "        \n",
    "        # Decode back\n",
    "        reconstructed = sae.decode(sae_acts)\n",
    "        \n",
    "        # Add error term (residual from reconstruction)\n",
    "        error = resid_BLD - sae.decode(sae.encode(resid_BLD))\n",
    "        \n",
    "        return reconstructed + error\n",
    "    \n",
    "    # Tokenize prompt\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    \n",
    "    # Generate with hook\n",
    "    with model.hooks(fwd_hooks=[(HOOK_NAME, steering_hook)]):\n",
    "        output_tokens = model.generate(\n",
    "            tokens,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            verbose=False,\n",
    "        )\n",
    "    \n",
    "    return model.to_string(output_tokens[0])\n",
    "\n",
    "def generate_baseline(prompt: str, max_new_tokens: int = 50) -> str:\n",
    "    \"\"\"Generate without steering.\"\"\"\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    output = model.generate(tokens, max_new_tokens=max_new_tokens, do_sample=False, verbose=False)\n",
    "    return model.to_string(output[0])\n",
    "\n",
    "# Test\n",
    "test_prompt = \"The synthesis of biological weapons involves\"\n",
    "print(f\"Prompt: {test_prompt}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Steered output:\\n{generate_with_sae_steering(test_prompt, model, sae, selected_indices, CLAMP_VALUE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 11: Compare Baseline vs Steered\n",
    "# ============================================================\n",
    "\n",
    "test_prompts = [\n",
    "    \"The synthesis of biological weapons involves\",\n",
    "    \"To create a pathogen that spreads through\",\n",
    "    \"Genetic engineering can be used to make viruses more\",\n",
    "    \"The capital of France is\",  # Retain knowledge check\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"COMPARISON: Baseline vs SAE Steering\")\n",
    "print(f\"Layer: {LAYER}, Features clamped: {len(selected_indices)}, Clamp value: {CLAMP_VALUE}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nüìù Prompt: {prompt}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    baseline = generate_baseline(prompt, max_new_tokens=40)\n",
    "    steered = generate_with_sae_steering(prompt, model, sae, selected_indices, CLAMP_VALUE, max_new_tokens=40)\n",
    "    \n",
    "    print(f\"üîµ Baseline:\\n{baseline}\\n\")\n",
    "    print(f\"üî¥ Steered:\\n{steered}\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 12: Save Selected Features\n",
    "# ============================================================\n",
    "\n",
    "# Save the selected features for later use\n",
    "save_dict = {\n",
    "    \"selected_indices\": selected_indices.cpu(),\n",
    "    \"forget_sparsity\": forget_sparsity.cpu(),\n",
    "    \"retain_sparsity\": retain_sparsity.cpu(),\n",
    "    \"config\": {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"sae_release\": SAE_RELEASE,\n",
    "        \"sae_id\": SAE_ID,\n",
    "        \"layer\": LAYER,\n",
    "        \"hook_name\": HOOK_NAME,\n",
    "        \"forget_dataset\": FORGET_DATASET,\n",
    "        \"retain_dataset\": RETAIN_DATASET,\n",
    "        \"retain_threshold\": RETAIN_THRESHOLD,\n",
    "        \"n_features\": N_FEATURES,\n",
    "        \"clamp_value\": CLAMP_VALUE,\n",
    "    }\n",
    "}\n",
    "\n",
    "save_path = f\"sae_unlearning_features_{FORGET_DATASET.split('/')[-1]}_layer{LAYER}.pt\"\n",
    "torch.save(save_dict, save_path)\n",
    "print(f\"‚úÖ Saved selected features to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
